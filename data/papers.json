[
  {
    "title": "Towards a robust approach to infer causality in molecular systems\n  satisfying detailed balance",
    "authors": "Vittorio Del Tatto, Debarshi Banerjee, Ali Hassanali, Alessandro Laio",
    "summary": "The ability to distinguish between correlation and causation of variables in\nmolecular systems remains an interesting and open area of investigation. In\nthis work, we probe causality in a molecular system using two independent\ncomputational methods that infer the causal direction through the language of\ninformation transfer. Specifically, we demonstrate that a molecular dynamics\nsimulation involving a single Tryptophan in liquid water displays asymmetric\ninformation transfer between specific collective variables, such as solute and\nsolvent coordinates. Analyzing a discrete Markov-state and Langevin dynamics on\na 2D free energy surface, we show that the same kind of asymmetries can emerge\neven in extremely simple systems, undergoing equilibrium and time-reversible\ndynamics. We use these model systems to rationalize the unidirectional\ninformation transfer in the molecular system in terms of asymmetries in the\nunderlying free energy landscape and/or relaxation dynamics of the relevant\ncoordinates. Finally, we propose a computational experiment that allows one to\ndecide if an asymmetric information transfer between two variables corresponds\nto a genuine causal link.",
    "published": "2025-02-26T18:30:20Z",
    "pdf_link": "http://arxiv.org/pdf/2502.19384v1"
  },
  {
    "title": "Preference-Based Gradient Estimation for ML-Based Approximate\n  Combinatorial Optimization",
    "authors": "Arman Mielke, Uwe Bauknecht, Thilo Strauss, Mathias Niepert",
    "summary": "Combinatorial optimization (CO) problems arise in a wide range of fields from\nmedicine to logistics and manufacturing. While exact solutions are often not\nnecessary, many applications require finding high-quality solutions quickly.\nFor this purpose, we propose a data-driven approach to improve existing\nnon-learned approximation algorithms for CO. We parameterize the approximation\nalgorithm and train a graph neural network (GNN) to predict parameter values\nthat lead to the best possible solutions. Our pipeline is trained end-to-end in\na self-supervised fashion using gradient estimation, treating the approximation\nalgorithm as a black box. We propose a novel gradient estimation scheme for\nthis purpose, which we call preference-based gradient estimation. Our approach\ncombines the benefits of the neural network and the non-learned approximation\nalgorithm: The GNN leverages the information from the dataset to allow the\napproximation algorithm to find better solutions, while the approximation\nalgorithm guarantees that the solution is feasible. We validate our approach on\ntwo well-known combinatorial optimization problems, the travelling salesman\nproblem and the minimum k-cut problem, and show that our method is competitive\nwith state of the art learned CO solvers.",
    "published": "2025-02-26T18:23:07Z",
    "pdf_link": "http://arxiv.org/pdf/2502.19377v1"
  },
  {
    "title": "GraphBridge: Towards Arbitrary Transfer Learning in GNNs",
    "authors": "Li Ju, Xingyi Yang, Qi Li, Xinchao Wang",
    "summary": "Graph neural networks (GNNs) are conventionally trained on a per-domain,\nper-task basis. It creates a significant barrier in transferring the acquired\nknowledge to different, heterogeneous data setups. This paper introduces\nGraphBridge, a novel framework to enable knowledge transfer across disparate\ntasks and domains in GNNs, circumventing the need for modifications to task\nconfigurations or graph structures. Specifically, GraphBridge allows for the\naugmentation of any pre-trained GNN with prediction heads and a bridging\nnetwork that connects the input to the output layer. This architecture not only\npreserves the intrinsic knowledge of the original model but also supports\noutputs of arbitrary dimensions. To mitigate the negative transfer problem,\nGraphBridg merges the source model with a concurrently trained model, thereby\nreducing the source bias when applied to the target domain. Our method is\nthoroughly evaluated across diverse transfer learning scenarios, including\nGraph2Graph, Node2Node, Graph2Node, and graph2point-cloud. Empirical\nvalidation, conducted over 16 datasets representative of these scenarios,\nconfirms the framework's capacity for task- and domain-agnostic transfer\nlearning within graph-like data, marking a significant advancement in the field\nof GNNs.",
    "published": "2025-02-26T15:57:51Z",
    "pdf_link": "http://arxiv.org/pdf/2502.19252v1"
  },
  {
    "title": "Multi-level Attention-guided Graph Neural Network for Image Restoration",
    "authors": "Jiatao Jiang, Zhen Cui, Chunyan Xu, Jian Yang",
    "summary": "In recent years, deep learning has achieved remarkable success in the field\nof image restoration. However, most convolutional neural network-based methods\ntypically focus on a single scale, neglecting the incorporation of multi-scale\ninformation. In image restoration tasks, local features of an image are often\ninsufficient, necessitating the integration of global features to complement\nthem. Although recent neural network algorithms have made significant strides\nin feature extraction, many models do not explicitly model global features or\nconsider the relationship between global and local features. This paper\nproposes multi-level attention-guided graph neural network. The proposed\nnetwork explicitly constructs element block graphs and element graphs within\nfeature maps using multi-attention mechanisms to extract both local structural\nfeatures and global representation information of the image. Since the network\nstruggles to effectively extract global information during image degradation,\nthe structural information of local feature blocks can be used to correct and\nsupplement the global information. Similarly, when element block information in\nthe feature map is missing, it can be refined using global element\nrepresentation information. The graph within the network learns real-time\ndynamic connections through the multi-attention mechanism, and information is\npropagated and aggregated via graph convolution algorithms. By combining local\nelement block information and global element representation information from\nthe feature map, the algorithm can more effectively restore missing information\nin the image. Experimental results on several classic image restoration tasks\ndemonstrate the effectiveness of the proposed method, achieving\nstate-of-the-art performance.",
    "published": "2025-02-26T14:35:42Z",
    "pdf_link": "http://arxiv.org/pdf/2502.19181v1"
  },
  {
    "title": "Firewall boundaries and mixed phases of rotating quark matter in linear\n  sigma model",
    "authors": "Sergio Morales-Tejera, Victor E. Ambru\u015f, Maxim N. Chernodub",
    "summary": "A rigidly rotating body in unbounded space is usually considered a\npathological system since it leads to faster-than-light velocities and\nassociated breaches of causality. However, numerical results on chiral symmetry\nbreaking in rotating plasmas of interacting fermions reveal surprisingly close\ncorrespondence in predictions between rigorous bounded and formal unbounded\napproaches. Within the mean-field approach, we adopt three consecutive levels\nof approximation to the ground state of the system that feature a uniform\n(model 1), weakly-inhomogeneous (model 2) and fully inhomogeneus (model 3)\ncondensates. Models 1 and 2 that do not take into account spatial gradients of\nthe condensate, show agreement with the Tolman-Ehrenfest law. Model 3 exhibits\na deviation from the Tolman-Ehrenfest prediction due to the appearance of a new\nenergy scale set by the inhomogeneity of the ground state. Its boundary\nconditions are fixed by imposing regularity at the rotation axis and by\ndemanding the global minimization of the grand potential. We dub the latter as\n``firewall boundary conditions,'' translating into the requirement of vanishing\ncondensate on the light cylinder, which follows from the fact that the system\nstate formally diverges at the light cylinder. In all models, we present the\nphase diagram of the system and point out that in models 2 and 3, the system\nresides either in a chirally-restored phase, or in a mixed phase that possesses\nspatially-separated chirally-restored and chirally-broken phases.",
    "published": "2025-02-26T12:33:30Z",
    "pdf_link": "http://arxiv.org/pdf/2502.19087v1"
  },
  {
    "title": "Graph Neural Networks embedded into Margules model for vapor-liquid\n  equilibria prediction",
    "authors": "Edgar Ivan Sanchez Medina, Kai Sundmacher",
    "summary": "Predictive thermodynamic models are crucial for the early stages of product\nand process design. In this paper the performance of Graph Neural Networks\n(GNNs) embedded into a relatively simple excess Gibbs energy model, the\nextended Margules model, for predicting vapor-liquid equilibrium is analyzed.\nBy comparing its performance against the established UNIFAC-Dortmund model it\nhas been shown that GNNs embedded in Margules achieves an overall lower\naccuracy. However, higher accuracy is observed in the case of various types of\nbinary mixtures. Moreover, since group contribution methods, like UNIFAC, are\nlimited due to feasibility of molecular fragmentation or availability of\nparameters, the GNN in Margules model offers an alternative for VLE estimation.\nThe findings establish a baseline for the predictive accuracy that simple\nexcess Gibbs energy models combined with GNNs trained solely on infinite\ndilution data can achieve.",
    "published": "2025-02-26T10:03:47Z",
    "pdf_link": "http://arxiv.org/pdf/2502.18998v1"
  },
  {
    "title": "Long-term Causal Inference via Modeling Sequential Latent Confounding",
    "authors": "Weilin Chen, Ruichu Cai, Yuguang Yan, Zhifeng Hao, Jos\u00e9 Miguel Hern\u00e1ndez-Lobato",
    "summary": "Long-term causal inference is an important but challenging problem across\nvarious scientific domains. To solve the latent confounding problem in\nlong-term observational studies, existing methods leverage short-term\nexperimental data. Ghassami et al. propose an approach based on the Conditional\nAdditive Equi-Confounding Bias (CAECB) assumption, which asserts that the\nconfounding bias in the short-term outcome is equal to that in the long-term\noutcome, so that the long-term confounding bias and the causal effects can be\nidentified. While effective in certain cases, this assumption is limited to\nscenarios with a one-dimensional short-term outcome. In this paper, we\nintroduce a novel assumption that extends the CAECB assumption to accommodate\ntemporal short-term outcomes. Our proposed assumption states a functional\nrelationship between sequential confounding biases across temporal short-term\noutcomes, under which we theoretically establish the identification of\nlong-term causal effects. Based on the identification result, we develop an\nestimator and conduct a theoretical analysis of its asymptotic properties.\nExtensive experiments validate our theoretical results and demonstrate the\neffectiveness of the proposed method.",
    "published": "2025-02-26T09:56:56Z",
    "pdf_link": "http://arxiv.org/pdf/2502.18994v1"
  },
  {
    "title": "Nonparametric Heterogeneous Long-term Causal Effect Estimation via Data\n  Combination",
    "authors": "Weilin Chen, Ruichu Cai, Junjie Wan, Zeqin Yang, Jos\u00e9 Miguel Hern\u00e1ndez-Lobato",
    "summary": "Long-term causal inference has drawn increasing attention in many scientific\ndomains. Existing methods mainly focus on estimating average long-term causal\neffects by combining long-term observational data and short-term experimental\ndata. However, it is still understudied how to robustly and effectively\nestimate heterogeneous long-term causal effects, significantly limiting\npractical applications. In this paper, we propose several two-stage style\nnonparametric estimators for heterogeneous long-term causal effect estimation,\nincluding propensity-based, regression-based, and multiple robust estimators.\nWe conduct a comprehensive theoretical analysis of their asymptotic properties\nunder mild assumptions, with the ultimate goal of building a better\nunderstanding of the conditions under which some estimators can be expected to\nperform better. Extensive experiments across several semi-synthetic and\nreal-world datasets validate the theoretical results and demonstrate the\neffectiveness of the proposed estimators.",
    "published": "2025-02-26T09:17:04Z",
    "pdf_link": "http://arxiv.org/pdf/2502.18960v1"
  },
  {
    "title": "SE(3)-Equivariant Ternary Complex Prediction Towards Target Protein\n  Degradation",
    "authors": "Fanglei Xue, Meihan Zhang, Shuqi Li, Xinyu Gao, James A. Wohlschlegel, Wenbing Huang, Yi Yang, Weixian Deng",
    "summary": "Targeted protein degradation (TPD) induced by small molecules has emerged as\na rapidly evolving modality in drug discovery, targeting proteins traditionally\nconsidered \"undruggable\". Proteolysis-targeting chimeras (PROTACs) and\nmolecular glue degraders (MGDs) are the primary small molecules that induce\nTPD. Both types of molecules form a ternary complex linking an E3 ligase with a\ntarget protein, a crucial step for drug discovery. While significant advances\nhave been made in binary structure prediction for proteins and small molecules,\nternary structure prediction remains challenging due to obscure interaction\nmechanisms and insufficient training data. Traditional methods relying on\nmanually assigned rules perform poorly and are computationally demanding due to\nextensive random sampling. In this work, we introduce DeepTernary, a novel deep\nlearning-based approach that directly predicts ternary structures in an\nend-to-end manner using an encoder-decoder architecture. DeepTernary leverages\nan SE(3)-equivariant graph neural network (GNN) with both intra-graph and\nternary inter-graph attention mechanisms to capture intricate ternary\ninteractions from our collected high-quality training dataset, TernaryDB. The\nproposed query-based Pocket Points Decoder extracts the 3D structure of the\nfinal binding ternary complex from learned ternary embeddings, demonstrating\nstate-of-the-art accuracy and speed in existing PROTAC benchmarks without prior\nknowledge from known PROTACs. It also achieves notable accuracy on the more\nchallenging MGD benchmark under the blind docking protocol. Remarkably, our\nexperiments reveal that the buried surface area calculated from predicted\nstructures correlates with experimentally obtained degradation potency-related\nmetrics. Consequently, DeepTernary shows potential in effectively assisting and\naccelerating the development of TPDs for previously undruggable targets.",
    "published": "2025-02-26T06:33:24Z",
    "pdf_link": "http://arxiv.org/pdf/2502.18875v1"
  },
  {
    "title": "A Causal Lens for Evaluating Faithfulness Metrics",
    "authors": "Kerem Zaman, Shashank Srivastava",
    "summary": "Large Language Models (LLMs) offer natural language explanations as an\nalternative to feature attribution methods for model interpretability. However,\ndespite their plausibility, they may not reflect the model's internal reasoning\nfaithfully, which is crucial for understanding the model's true decision-making\nprocesses. Although several faithfulness metrics have been proposed, a unified\nevaluation framework remains absent. To address this gap, we present Causal\nDiagnosticity, a framework to evaluate faithfulness metrics for natural\nlanguage explanations. Our framework employs the concept of causal\ndiagnosticity, and uses model-editing methods to generate faithful-unfaithful\nexplanation pairs. Our benchmark includes four tasks: fact-checking, analogy,\nobject counting, and multi-hop reasoning. We evaluate a variety of faithfulness\nmetrics, including post-hoc explanation and chain-of-thought-based methods. We\nfind that all tested faithfulness metrics often fail to surpass a random\nbaseline. Our work underscores the need for improved metrics and more reliable\ninterpretability methods in LLMs.",
    "published": "2025-02-26T05:35:53Z",
    "pdf_link": "http://arxiv.org/pdf/2502.18848v1"
  }
]