[
  {
    "title": "How Do LLMs Perform Two-Hop Reasoning in Context?",
    "authors": "Tianyu Guo, Hanlin Zhu, Ruiqi Zhang, Jiantao Jiao, Song Mei, Michael I. Jordan, Stuart Russell",
    "summary": "\"Socrates is human. All humans are mortal. Therefore, Socrates is mortal.\"\nThis classical example demonstrates two-hop reasoning, where a conclusion\nlogically follows from two connected premises. While transformer-based Large\nLanguage Models (LLMs) can make two-hop reasoning, they tend to collapse to\nrandom guessing when faced with distracting premises. To understand the\nunderlying mechanism, we train a three-layer transformer on synthetic two-hop\nreasoning tasks. The training dynamics show two stages: a slow learning phase,\nwhere the 3-layer transformer performs random guessing like LLMs, followed by\nan abrupt phase transitions, where the 3-layer transformer suddenly reaches\n$100%$ accuracy. Through reverse engineering, we explain the inner mechanisms\nfor how models learn to randomly guess between distractions initially, and how\nthey learn to ignore distractions eventually. We further propose a\nthree-parameter model that supports the causal claims for the mechanisms to the\ntraining dynamics of the transformer. Finally, experiments on LLMs suggest that\nthe discovered mechanisms generalize across scales. Our methodologies provide\nnew perspectives for scientific understandings of LLMs and our findings provide\nnew insights into how reasoning emerges during training.",
    "published": "2025-02-19T17:46:30Z",
    "pdf_link": "http://arxiv.org/pdf/2502.13913v1"
  },
  {
    "title": "Isometries of spacetimes without observer horizons",
    "authors": "Leonardo Garc\u00eda-Heveling, Abdelghani Zeghib",
    "summary": "We study the isometry groups of (non-compact) Lorentzian manifolds with\nwell-behaved causal structure, aka causal spacetimes satisfying the ``no\nobserver horizons'' condition. Our main result is that the group of time\norientation-preserving isometries acts properly on the spacetime. As\ncorollaries, we obtain the existence of an invariant Cauchy temporal function,\nand a splitting of the isometry group into a compact subgroup and a subgroup\nroughly corresponding to time translations. The latter can only be the trivial\ngroup, $\\mathbb{Z}$, or $\\mathbb{R}$.",
    "published": "2025-02-19T17:38:11Z",
    "pdf_link": "http://arxiv.org/pdf/2502.13904v1"
  },
  {
    "title": "Integrating Randomized Controlled Trial and External Control Data Using\n  Balancing Weights: A Comparison of Estimands and Estimators",
    "authors": "Peijin Wang, Hwanhee Hong, Kyungeun Jeon, Laine Elliott Thomas",
    "summary": "Randomized controlled trials (RCTs) face inherent limitations, such as\nethical or resource constraints, which lead to a limited number of study\nparticipants. To address these limitations, recent research endeavors have\nsought to incorporate external control (EC) data, such as historical trial data\nor real-world data, with RCT data in treatment effect evaluation. This\nintegration introduces unique questions regarding target population\nspecification, causal estimand, and optimality of pooled estimators. Balancing\nweights have emerged as valuable tools to ensure comparability in patient\ncharacteristics, but there remains a gap in implementing them with ECs. In this\nstudy, we elucidate potential estimands of interest and propose corresponding\nbalancing-weight-based estimators. We provide statistical and clinical\ndefinitions and interpretations of the estimands. Our extensive simulations\nshow that different causal estimands perform differently with respect to bias\nand efficiency, based on the level of similarity between RCT and EC.",
    "published": "2025-02-19T16:52:48Z",
    "pdf_link": "http://arxiv.org/pdf/2502.13871v1"
  },
  {
    "title": "Extending the RANGE of Graph Neural Networks: Relaying Attention Nodes\n  for Global Encoding",
    "authors": "Alessandro Caruso, Jacopo Venturin, Lorenzo Giambagli, Edoardo Rolando, Frank No\u00e9, Cecilia Clementi",
    "summary": "Graph Neural Networks (GNNs) are routinely used in molecular physics, social\nsciences, and economics to model many-body interactions in graph-like systems.\nHowever, GNNs are inherently local and can suffer from information flow\nbottlenecks. This is particularly problematic when modeling large molecular\nsystems, where dispersion forces and local electric field variations drive\ncollective structural changes. Existing solutions face challenges related to\ncomputational cost and scalability. We introduce RANGE, a model-agnostic\nframework that employs an attention-based aggregation-broadcast mechanism that\nsignificantly reduces oversquashing effects, and achieves remarkable accuracy\nin capturing long-range interactions at a negligible computational cost.\nNotably, RANGE is the first virtual-node message-passing implementation to\nintegrate attention with positional encodings and regularization to dynamically\nexpand virtual representations. This work lays the foundation for\nnext-generation of machine-learned force fields, offering accurate and\nefficient modeling of long-range interactions for simulating large molecular\nsystems.",
    "published": "2025-02-19T15:05:47Z",
    "pdf_link": "http://arxiv.org/pdf/2502.13797v1"
  },
  {
    "title": "Unsupervised Graph Embeddings for Session-based Recommendation with Item\n  Features",
    "authors": "Andreas Peintner, Marta Moscati, Emilia Parada-Cabaleiro, Markus Schedl, Eva Zangerle",
    "summary": "In session-based recommender systems, predictions are based on the user's\npreceding behavior in the session. State-of-the-art sequential recommendation\nalgorithms either use graph neural networks to model sessions in a graph or\nleverage the similarity of sessions by exploiting item features. In this paper,\nwe combine these two approaches and propose a novel method, Graph Convolutional\nNetwork Extension (GCNext), which incorporates item features directly into the\ngraph representation via graph convolutional networks. GCNext creates a\nfeature-rich item co-occurrence graph and learns the corresponding item\nembeddings in an unsupervised manner. We show on three datasets that\nintegrating GCNext into sequential recommendation algorithms significantly\nboosts the performance of nearest-neighbor methods as well as neural network\nmodels. Our flexible extension is easy to incorporate in state-of-the-art\nmethods and increases the MRR@20 by up to 12.79%.",
    "published": "2025-02-19T14:23:18Z",
    "pdf_link": "http://arxiv.org/pdf/2502.13763v1"
  },
  {
    "title": "Causal discovery in heavy-tailed linear structural equation models via\n  scalings",
    "authors": "Mario Krali",
    "summary": "Causal dependence modelling of multivariate extremes is intended to improve\nour understanding of the relationships amongst variables associated with rare\nevents. Regular variation provides a standard framework in the study of\nextremes. This paper concerns the linear structural equation model with\nregularly varying noise variables. We focus on extreme observations generated\nfrom such a model and propose a causal discovery method based on the scaling\nparameters of its extremal angular measure. We implement the method as an\nalgorithm, establish its consistency and evaluate it by simulation and by\napplication to river discharge datasets. Comparison with the only alternative\nextremal method for such model reveals its competitive performance.",
    "published": "2025-02-19T14:23:11Z",
    "pdf_link": "http://arxiv.org/pdf/2502.13762v1"
  },
  {
    "title": "D-separation for applied researchers: understanding how to interpret\n  directed acyclic graphs",
    "authors": "Fernando Pires Hartwig, Timothy Feeney, Neil Davies",
    "summary": "The assumed causal relationships depicted in a DAG are interpreted using a\nset of rules called D-separation rules. Although these rules can be implemented\nautomatically using standard software, at least a basic understanding of their\nprinciples is useful for properly using and interpreting DAGs in practice.",
    "published": "2025-02-19T14:03:11Z",
    "pdf_link": "http://arxiv.org/pdf/2502.13736v1"
  },
  {
    "title": "Homophily Heterogeneity Matters in Graph Federated Learning: A Spectrum\n  Sharing and Complementing Perspective",
    "authors": "Wentao Yu",
    "summary": "Since heterogeneity presents a fundamental challenge in graph federated\nlearning, many existing methods are proposed to deal with node feature\nheterogeneity and structure heterogeneity. However, they overlook the critical\nhomophily heterogeneity, which refers to the substantial variation in homophily\nlevels across graph data from different clients. The homophily level represents\nthe proportion of edges connecting nodes that belong to the same class. Due to\nadapting to their local homophily, local models capture inconsistent spectral\nproperties across different clients, significantly reducing the effectiveness\nof collaboration. Specifically, local models trained on graphs with high\nhomophily tend to capture low-frequency information, whereas local models\ntrained on graphs with low homophily tend to capture high-frequency\ninformation. To effectively deal with homophily heterophily, we introduce the\nspectral Graph Neural Network (GNN) and propose a novel Federated learning\nmethod by mining Graph Spectral Properties (FedGSP). On one hand, our proposed\nFedGSP enables clients to share generic spectral properties (i.e.,\nlow-frequency information), allowing all clients to benefit through\ncollaboration. On the other hand, inspired by our theoretical findings, our\nproposed FedGSP allows clients to complement non-generic spectral properties by\nacquiring the spectral properties they lack (i.e., high-frequency information),\nthereby obtaining additional information gain. Extensive experiments conducted\non six homophilic and five heterophilic graph datasets, across both\nnon-overlapping and overlapping settings, validate the superiority of our\nmethod over eleven state-of-the-art methods. Notably, our FedGSP outperforms\nthe second-best method by an average margin of 3.28% on all heterophilic\ndatasets.",
    "published": "2025-02-19T13:58:08Z",
    "pdf_link": "http://arxiv.org/pdf/2502.13732v1"
  },
  {
    "title": "Robust Counterfactual Inference in Markov Decision Processes",
    "authors": "Jessica Lally, Milad Kazemi, Nicola Paoletti",
    "summary": "This paper addresses a key limitation in existing counterfactual inference\nmethods for Markov Decision Processes (MDPs). Current approaches assume a\nspecific causal model to make counterfactuals identifiable. However, there are\nusually many causal models that align with the observational and interventional\ndistributions of an MDP, each yielding different counterfactual distributions,\nso fixing a particular causal model limits the validity (and usefulness) of\ncounterfactual inference. We propose a novel non-parametric approach that\ncomputes tight bounds on counterfactual transition probabilities across all\ncompatible causal models. Unlike previous methods that require solving\nprohibitively large optimisation problems (with variables that grow\nexponentially in the size of the MDP), our approach provides closed-form\nexpressions for these bounds, making computation highly efficient and scalable\nfor non-trivial MDPs. Once such an interval counterfactual MDP is constructed,\nour method identifies robust counterfactual policies that optimise the\nworst-case reward w.r.t. the uncertain interval MDP probabilities. We evaluate\nour method on various case studies, demonstrating improved robustness over\nexisting methods.",
    "published": "2025-02-19T13:56:20Z",
    "pdf_link": "http://arxiv.org/pdf/2502.13731v1"
  },
  {
    "title": "Causes and Strategies in Multiagent Systems",
    "authors": "Sylvia S. Kerkhove, Natasha Alechina, Mehdi Dastani",
    "summary": "Causality plays an important role in daily processes, human reasoning, and\nartificial intelligence. There has however not been much research on causality\nin multi-agent strategic settings. In this work, we introduce a systematic way\nto build a multi-agent system model, represented as a concurrent game\nstructure, for a given structural causal model. In the obtained so-called\ncausal concurrent game structure, transitions correspond to interventions on\nagent variables of the given causal model. The Halpern and Pearl framework of\ncausality is used to determine the effects of a certain value for an agent\nvariable on other variables. The causal concurrent game structure allows us to\nanalyse and reason about causal effects of agents' strategic decisions. We\nformally investigate the relation between causal concurrent game structures and\nthe original structural causal models.",
    "published": "2025-02-19T13:18:42Z",
    "pdf_link": "http://arxiv.org/pdf/2502.13701v1"
  }
]