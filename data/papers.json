[
  {
    "title": "Representation and Interpretation in Artificial and Natural Computing",
    "authors": "Luis A. Pineda",
    "summary": "Artificial computing machinery transforms representations through an\nobjective process, to be interpreted subjectively by humans, so the machine and\nthe interpreter are different entities, but in the putative natural computing\nboth processes are performed by the same agent. The method or process that\ntransforms a representation is called here \\emph{the mode of computing}. The\nmode used by digital computers is the algorithmic one, but there are others,\nsuch as quantum computers and diverse forms of non-conventional computing, and\nthere is an open-ended set of representational formats and modes that could be\nused in artificial and natural computing. A mode based on a notion of computing\ndifferent from Turing's may perform feats beyond what the Turing Machine does\nbut the modes would not be of the same kind and could not be compared. For a\nmode of computing to be more powerful than the algorithmic one, it ought to\ncompute functions lacking an effective algorithm, and Church Thesis would not\nhold. Here, a thought experiment including a computational demon using a\nhypothetical mode for such an effect is presented. If there is natural\ncomputing, there is a mode of natural computing whose properties may be causal\nto the phenomenological experience. Discovering it would come with solving the\nhard problem of consciousness; but if it turns out that such a mode does not\nexist, there is no such thing as natural computing, and the mind is not a\ncomputational process.",
    "published": "2025-02-14T18:57:29Z",
    "pdf_link": "http://arxiv.org/pdf/2502.10383v1"
  },
  {
    "title": "Scalar weak gravity bound from full unitarity",
    "authors": "Anna Tokareva, Yongjun Xu",
    "summary": "Weak gravity conjecture can be formulated as a statement that gravity must be\nthe weakest force, compared to the other interactions in low energy effective\nfield theory (EFT). Several arguments in favor of this statement were presented\nfrom the side of string theory and black hole physics. However, it is still an\nopen question whether the statement of weak gravity can be proven based on more\ngeneral assumptions of causality, unitarity, and locality of the fundamental\ntheory. These consistency requirements imply the dispersion relations for the\nscattering amplitudes which allow to bound the EFT coefficients. The main\ndifficulty for obtaining these constraints in the presence of gravity is\nrelated to the graviton pole which makes the required dispersion relations\ndivergent in the forward limit. In this work, we present a new way of deriving\nthe bound on the ratio between the EFT cutoff scale and Planck mass from\nconfronting the IR divergences from graviton pole and one-loop running of the\nEFT Wilson coefficient in front of the dimension-12 operator. Our method also\nallows the incorporation of full unitarity of partial wave expansion of the UV\ntheory. We examine the EFT of a single shift-symmetric scalar in four\ndimensions and find that the maximal value of the cutoff scale of the EFT\ncoupled to gravity must be lower than about $O(10)$ Planck mass.",
    "published": "2025-02-14T18:53:38Z",
    "pdf_link": "http://arxiv.org/pdf/2502.10375v1"
  },
  {
    "title": "A Mechanistic Framework for Collider Detection in Observational Data",
    "authors": "Soumik Purkayastha, Peter X. -K. Song",
    "summary": "Understanding directionality is crucial for identifying causal structures\nfrom observational data. A key challenge lies in detecting collider structures,\nwhere a $V$--structure is formed between a child node $Z$ receiving directed\nedges from parents $X$ and $Y$, denoted by $X \\rightarrow Z \\leftarrow Y$.\nTraditional causal discovery approaches, such as constraint-based and\nscore-based structure learning algorithms, do not provide statistical inference\non estimated pathways and are often sensitive to latent confounding. To\novercome these issues, we introduce methodology to quantify directionality in\ncollider structures using a pair of conditional asymmetry coefficients to\nsimultaneously examine validity of the pathways $Y \\rightarrow Z$ and $X\n\\rightarrow Z$ in the collider structure. These coefficients are based on\nShannon's differential entropy. Leveraging kernel-based conditional density\nestimation and a nonparametric smoothing technique, we utilise our proposed\nmethod to estimate collider structures and provide uncertainty quantification.\n  Simulation studies demonstrate that our method outperforms existing structure\nlearning algorithms in accurately identifying collider structures. We further\napply our approach to investigate the role of blood pressure as a collider in\nepigenetic DNA methylation, uncovering novel insights into the genetic\nregulation of blood pressure. This framework represents a significant\nadvancement in causal structure learning, offering a robust, nonparametric\nmethod for collider detection with practical applications in biostatistics and\nepidemiology.",
    "published": "2025-02-14T17:20:34Z",
    "pdf_link": "http://arxiv.org/pdf/2502.10317v1"
  },
  {
    "title": "A Latent Causal Inference Framework for Ordinal Variables",
    "authors": "Martina Scauda, Jack Kuipers, Giusi Moffa",
    "summary": "Ordinal variables, such as on the Likert scale, are common in applied\nresearch. Yet, existing methods for causal inference tend to target nominal or\ncontinuous data. When applied to ordinal data, this fails to account for the\ninherent ordering or imposes well-defined relative magnitudes. Hence, there is\na need for specialised methods to compute interventional effects between\nordinal variables while accounting for their ordinality. One potential\nframework is to presume a latent Gaussian Directed Acyclic Graph (DAG) model:\nthat the ordinal variables originate from marginally discretizing a set of\nGaussian variables whose latent covariance matrix is constrained to satisfy the\nconditional independencies inherent in a DAG. Conditioned on a given latent\ncovariance matrix and discretisation thresholds, we derive a closed-form\nfunction for ordinal causal effects in terms of interventional distributions in\nthe latent space. Our causal estimation combines naturally with algorithms to\nlearn the latent DAG and its parameters, like the Ordinal Structural EM\nalgorithm. Simulations demonstrate the applicability of the proposed approach\nin estimating ordinal causal effects both for known and unknown structures of\nthe latent graph. As an illustration of a real-world use case, the method is\napplied to survey data of 408 patients from a study on the functional\nrelationships between symptoms of obsessive-compulsive disorder and depression.",
    "published": "2025-02-14T16:33:21Z",
    "pdf_link": "http://arxiv.org/pdf/2502.10276v1"
  },
  {
    "title": "Do Large Language Models Reason Causally Like Us? Even Better?",
    "authors": "Hanna M. Dettki, Brenden M. Lake, Charley M. Wu, Bob Rehder",
    "summary": "Causal reasoning is a core component of intelligence. Large language models\n(LLMs) have shown impressive capabilities in generating human-like text,\nraising questions about whether their responses reflect true understanding or\nstatistical patterns. We compared causal reasoning in humans and four LLMs\nusing tasks based on collider graphs, rating the likelihood of a query variable\noccurring given evidence from other variables. We find that LLMs reason\ncausally along a spectrum from human-like to normative inference, with\nalignment shifting based on model, context, and task. Overall, GPT-4o and\nClaude showed the most normative behavior, including \"explaining away\", whereas\nGemini-Pro and GPT-3.5 did not. Although all agents deviated from the expected\nindependence of causes - Claude the least - they exhibited strong associative\nreasoning and predictive inference when assessing the likelihood of the effect\ngiven its causes. These findings underscore the need to assess AI biases as\nthey increasingly assist human decision-making.",
    "published": "2025-02-14T15:09:15Z",
    "pdf_link": "http://arxiv.org/pdf/2502.10215v1"
  },
  {
    "title": "SGS-GNN: A Supervised Graph Sparsification method for Graph Neural\n  Networks",
    "authors": "Siddhartha Shankar Das, Naheed Anjum Arafat, Muftiqur Rahman, S M Ferdous, Alex Pothen, Mahantesh M Halappanavar",
    "summary": "We propose SGS-GNN, a novel supervised graph sparsifier that learns the\nsampling probability distribution of edges and samples sparse subgraphs of a\nuser-specified size to reduce the computational costs required by GNNs for\ninference tasks on large graphs. SGS-GNN employs regularizers in the loss\nfunction to enhance homophily in sparse subgraphs, boosting the accuracy of\nGNNs on heterophilic graphs, where a significant number of the neighbors of a\nnode have dissimilar labels. SGS-GNN also supports conditional updates of the\nprobability distribution learning module based on a prior, which helps narrow\nthe search space for sparse graphs. SGS-GNN requires fewer epochs to obtain\nhigh accuracies since it learns the search space of subgraphs more effectively\nthan methods using fixed distributions such as random sampling. Extensive\nexperiments using 33 homophilic and heterophilic graphs demonstrate the\nfollowing: (i) with only 20% of edges retained in the sparse subgraphs, SGS-GNN\nimproves the F1-scores by a geometric mean of 4% relative to the original\ngraph; on heterophilic graphs, the prediction accuracy is better up to 30%.\n(ii) SGS-GNN outperforms state-of-the-art methods with improvement in F1-scores\nof 4-7% in geometric mean with similar sparsities in the sampled subgraphs, and\n(iii) compared to sparsifiers that employ fixed distributions, SGS-GNN requires\nabout half the number of epochs to converge.",
    "published": "2025-02-14T15:03:43Z",
    "pdf_link": "http://arxiv.org/pdf/2502.10208v1"
  },
  {
    "title": "Revisiting the Berkeley Admissions data: Statistical Tests for Causal\n  Hypotheses",
    "authors": "Sourbh Bhadane, Joris M. Mooij, Philip Boeken, Onno Zoeter",
    "summary": "Reasoning about fairness through correlation-based notions is rife with\npitfalls. The 1973 University of California, Berkeley graduate school\nadmissions case from Bickel et. al. (1975) is a classic example of one such\npitfall, namely Simpson's paradox. The discrepancy in admission rates among\nmales and female applicants, in the aggregate data over all departments,\nvanishes when admission rates per department are examined. We reason about the\nBerkeley graduate school admissions case through a causal lens. In the process,\nwe introduce a statistical test for causal hypothesis testing based on Pearl's\ninstrumental-variable inequalities (Pearl 1995). We compare different causal\nnotions of fairness that are based on graphical, counterfactual and\ninterventional queries on the causal model, and develop statistical tests for\nthese notions that use only observational data. We study the logical relations\nbetween notions, and show that while notions may not be equivalent, their\ncorresponding statistical tests coincide for the case at hand. We believe that\na thorough case-based causal analysis helps develop a more principled\nunderstanding of both causal hypothesis testing and fairness.",
    "published": "2025-02-14T13:43:35Z",
    "pdf_link": "http://arxiv.org/pdf/2502.10161v1"
  },
  {
    "title": "COMBINEX: A Unified Counterfactual Explainer for Graph Neural Networks\n  via Node Feature and Structural Perturbations",
    "authors": "Flavio Giorgi, Fabrizio Silvestri, Gabriele Tolomei",
    "summary": "Counterfactual explanations have emerged as a powerful tool to unveil the\nopaque decision-making processes of graph neural networks (GNNs). However,\nexisting techniques primarily focus on edge modifications, often overlooking\nthe crucial role of node feature perturbations in shaping model predictions. To\naddress this limitation, we propose COMBINEX, a novel GNN explainer that\ngenerates counterfactual explanations for both node and graph classification\ntasks. Unlike prior methods, which treat structural and feature-based changes\nindependently, COMBINEX optimally balances modifications to edges and node\nfeatures by jointly optimizing these perturbations. This unified approach\nensures minimal yet effective changes required to flip a model's prediction,\nresulting in realistic and interpretable counterfactuals. Additionally,\nCOMBINEX seamlessly handles both continuous and discrete node features,\nenhancing its versatility across diverse datasets and GNN architectures.\nExtensive experiments on real-world datasets and various GNN architectures\ndemonstrate the effectiveness and robustness of our approach over existing\nbaselines.",
    "published": "2025-02-14T12:17:24Z",
    "pdf_link": "http://arxiv.org/pdf/2502.10111v1"
  },
  {
    "title": "Causal Information Prioritization for Efficient Reinforcement Learning",
    "authors": "Hongye Cao, Fan Feng, Tianpei Yang, Jing Huo, Yang Gao",
    "summary": "Current Reinforcement Learning (RL) methods often suffer from\nsample-inefficiency, resulting from blind exploration strategies that neglect\ncausal relationships among states, actions, and rewards. Although recent causal\napproaches aim to address this problem, they lack grounded modeling of\nreward-guided causal understanding of states and actions for goal-orientation,\nthus impairing learning efficiency. To tackle this issue, we propose a novel\nmethod named Causal Information Prioritization (CIP) that improves sample\nefficiency by leveraging factored MDPs to infer causal relationships between\ndifferent dimensions of states and actions with respect to rewards, enabling\nthe prioritization of causal information. Specifically, CIP identifies and\nleverages causal relationships between states and rewards to execute\ncounterfactual data augmentation to prioritize high-impact state features under\nthe causal understanding of the environments. Moreover, CIP integrates a\ncausality-aware empowerment learning objective, which significantly enhances\nthe agent's execution of reward-guided actions for more efficient exploration\nin complex environments. To fully assess the effectiveness of CIP, we conduct\nextensive experiments across 39 tasks in 5 diverse continuous control\nenvironments, encompassing both locomotion and manipulation skills learning\nwith pixel-based and sparse reward settings. Experimental results demonstrate\nthat CIP consistently outperforms existing RL methods across a wide range of\nscenarios.",
    "published": "2025-02-14T11:44:17Z",
    "pdf_link": "http://arxiv.org/pdf/2502.10097v1"
  },
  {
    "title": "Towards Empowerment Gain through Causal Structure Learning in\n  Model-Based RL",
    "authors": "Hongye Cao, Fan Feng, Meng Fang, Shaokang Dong, Tianpei Yang, Jing Huo, Yang Gao",
    "summary": "In Model-Based Reinforcement Learning (MBRL), incorporating causal structures\ninto dynamics models provides agents with a structured understanding of the\nenvironments, enabling efficient decision. Empowerment as an intrinsic\nmotivation enhances the ability of agents to actively control their\nenvironments by maximizing the mutual information between future states and\nactions. We posit that empowerment coupled with causal understanding can\nimprove controllability, while enhanced empowerment gain can further facilitate\ncausal reasoning in MBRL. To improve learning efficiency and controllability,\nwe propose a novel framework, Empowerment through Causal Learning (ECL), where\nan agent with the awareness of causal dynamics models achieves\nempowerment-driven exploration and optimizes its causal structure for task\nlearning. Specifically, ECL operates by first training a causal dynamics model\nof the environment based on collected data. We then maximize empowerment under\nthe causal structure for exploration, simultaneously using data gathered\nthrough exploration to update causal dynamics model to be more controllable\nthan dense dynamics model without causal structure. In downstream task\nlearning, an intrinsic curiosity reward is included to balance the causality,\nmitigating overfitting. Importantly, ECL is method-agnostic and is capable of\nintegrating various causal discovery methods. We evaluate ECL combined with 3\ncausal discovery methods across 6 environments including pixel-based tasks,\ndemonstrating its superior performance compared to other causal MBRL methods,\nin terms of causal discovery, sample efficiency, and asymptotic performance.",
    "published": "2025-02-14T10:59:09Z",
    "pdf_link": "http://arxiv.org/pdf/2502.10077v1"
  }
]