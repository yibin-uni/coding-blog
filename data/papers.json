[
  {
    "title": "Multi-Objective Causal Bayesian Optimization",
    "authors": "Shriya Bhatija, Paul-David Zuercher, Jakob Thumm, Thomas Bohn\u00e9",
    "summary": "In decision-making problems, the outcome of an intervention often depends on\nthe causal relationships between system components and is highly costly to\nevaluate. In such settings, causal Bayesian optimization (CBO) can exploit the\ncausal relationships between the system variables and sequentially perform\ninterventions to approach the optimum with minimal data. Extending CBO to the\nmulti-outcome setting, we propose Multi-Objective Causal Bayesian Optimization\n(MO-CBO), a paradigm for identifying Pareto-optimal interventions within a\nknown multi-target causal graph. We first derive a graphical characterization\nfor potentially optimal sets of variables to intervene upon. Showing that any\nMO-CBO problem can be decomposed into several traditional multi-objective\noptimization tasks, we then introduce an algorithm that sequentially balances\nexploration across these tasks using relative hypervolume improvement. The\nproposed method will be validated on both synthetic and real-world causal\ngraphs, demonstrating its superiority over traditional (non-causal)\nmulti-objective Bayesian optimization in settings where causal information is\navailable.",
    "published": "2025-02-20T17:26:16Z",
    "pdf_link": "http://arxiv.org/pdf/2502.14755v1"
  },
  {
    "title": "Internal Incoherency Scores for Constraint-based Causal Discovery\n  Algorithms",
    "authors": "Sofia Faltenbacher, Jonas Wahl, Rebecca Herman, Jakob Runge",
    "summary": "Causal discovery aims to infer causal graphs from observational or\nexperimental data. Methods such as the popular PC algorithm are based on\nconditional independence testing and utilize enabling assumptions, such as the\nfaithfulness assumption, for their inferences. In practice, these assumptions,\nas well as the functional assumptions inherited from the chosen conditional\nindependence test, are typically taken as a given and not further tested for\ntheir validity on the data. In this work, we propose internal coherency scores\nthat allow testing for assumption violations and finite sample errors, whenever\ndetectable without requiring ground truth or further statistical tests. We\nprovide a complete classification of erroneous results, including a distinction\nbetween detectable and undetectable errors, and prove that the detectable\nerroneous results can be measured by our scores. We illustrate our coherency\nscores on the PC algorithm with simulated and real-world datasets, and envision\nthat testing for internal coherency can become a standard tool in applying\nconstraint-based methods, much like a suite of tests is used to validate the\nassumptions of classical regression analysis.",
    "published": "2025-02-20T16:44:54Z",
    "pdf_link": "http://arxiv.org/pdf/2502.14719v1"
  },
  {
    "title": "Outlier Detection in Mendelian Randomisation",
    "authors": "Maximilian M Mandl, Anne-Laure Boulesteix, Stephen Burgess, Verena Zuber",
    "summary": "Mendelian Randomisation (MR) uses genetic variants as instrumental variables\nto infer causal effects of exposures on an outcome. One key assumption of MR is\nthat the genetic variants used as instrumental variables are independent of the\noutcome conditional on the risk factor and unobserved confounders. Violations\nof this assumption, i.e. the effect of the instrumental variables on the\noutcome through a path other than the risk factor included in the model (which\ncan be caused by pleiotropy), are common phenomena in human genetics. Genetic\nvariants, which deviate from this assumption, appear as outliers to the MR\nmodel fit and can be detected by the general heterogeneity statistics proposed\nin the literature, which are known to suffer from overdispersion, i.e. too many\ngenetic variants are declared as false outliers. We propose a method that\ncorrects for overdispersion of the heterogeneity statistics in uni- and\nmultivariable MR analysis by making use of the estimated inflation factor to\ncorrectly remove outlying instruments and therefore account for pleiotropic\neffects. Our method is applicable to summary-level data.",
    "published": "2025-02-20T16:42:09Z",
    "pdf_link": "http://arxiv.org/pdf/2502.14716v1"
  },
  {
    "title": "Nonadiabatic quantum geometry and optical conductivity",
    "authors": "Raffaele Resta",
    "summary": "The ground-state quantum geometry is at the root of several static and\nadiabatic properties, while genuinely dynamic properties are routinely\naddressed via Kubo formulae, whose essential entries are the excited states. It\nis shown here that the ground-state metric-curvature tensor evolves in time by\nmeans of a causal unitary operator, which by construction elucidates the\ngeometrical effect of the excited states in compact form. In the\ncondensed-matter case the generalized tensor encompasses the whole conductivity\ntensor at arbitrary frequencies in both insulators and metals, with the\nexception of the Drude term in the metallic case; the latter is shown to be\neminently nongeometrical.",
    "published": "2025-02-20T16:21:52Z",
    "pdf_link": "http://arxiv.org/pdf/2502.14697v1"
  },
  {
    "title": "Reward Models Identify Consistency, Not Causality",
    "authors": "Yuhui Xu, Hanze Dong, Lei Wang, Caiming Xiong, Junnan Li",
    "summary": "Reward models (RMs) play a crucial role in aligning large language models\n(LLMs) with human preferences and enhancing reasoning quality. Traditionally,\nRMs are trained to rank candidate outputs based on their correctness and\ncoherence. However, in this work, we present several surprising findings that\nchallenge common assumptions about RM behavior. Our analysis reveals that\nstate-of-the-art reward models prioritize structural consistency over causal\ncorrectness. Specifically, removing the problem statement has minimal impact on\nreward scores, whereas altering numerical values or disrupting the reasoning\nflow significantly affects RM outputs. Furthermore, RMs exhibit a strong\ndependence on complete reasoning trajectories truncated or incomplete steps\nlead to significant variations in reward assignments, indicating that RMs\nprimarily rely on learned reasoning patterns rather than explicit problem\ncomprehension. These findings hold across multiple architectures, datasets, and\ntasks, leading to three key insights: (1) RMs primarily assess coherence rather\nthan true reasoning quality; (2) The role of explicit problem comprehension in\nreward assignment is overstated; (3) Current RMs may be more effective at\nranking responses than verifying logical validity. Our results suggest a\nfundamental limitation in existing reward modeling approaches, emphasizing the\nneed for a shift toward causality-aware reward models that go beyond\nconsistency-driven evaluation.",
    "published": "2025-02-20T14:57:14Z",
    "pdf_link": "http://arxiv.org/pdf/2502.14619v1"
  },
  {
    "title": "Addressing Positivity Violations in Continuous Interventions through\n  Data-Adaptive Strategies",
    "authors": "Han Bao, Michael Schomaker",
    "summary": "Positivity violations pose a key challenge in the estimation of causal\neffects, particularly for continuous interventions. Current approaches for\naddressing this issue include the use of projection functions or modified\ntreatment policies. While effective in many contexts, these methods can result\nin estimands that potentially do not align well with the original research\nquestion, thereby leading to compromises in interpretability. In this paper, we\nintroduce a novel diagnostic tool, the non-overlap ratio, to detect positivity\nviolations. To address these violations while maintaining interpretability, we\npropose a data-adaptive solution, specially a \"most feasible\" intervention\nstrategy. Our strategy operates on a unit-specific basis. For a given\nintervention of interest, we first assess whether the intervention value is\nfeasible for each unit. For units with sufficient support, conditional on\nconfounders, we adhere to the intervention of interest. However, for units\nlacking sufficient support, as identified through the assessment of the\nnon-overlap ratio, we do not assign the actual intervention value of interest.\nInstead, we assign the closest feasible value within the support region. We\npropose an estimator using g-computation coupled with flexible conditional\ndensity estimation to estimate high- and low support regions to estimate this\nnew estimand. Through simulations, we demonstrate that our method effectively\nreduces bias across various scenarios by addressing positivity violations.\nMoreover, when positivity violations are absent, the method successfully\nrecovers the standard estimand. We further validate its practical utility using\nreal-world data from the CHAPAS-3 trial, which enrolled HIV-positive children\nin Zambia and Uganda.",
    "published": "2025-02-20T13:51:08Z",
    "pdf_link": "http://arxiv.org/pdf/2502.14566v1"
  },
  {
    "title": "Multiscale Byte Language Models -- A Hierarchical Architecture for\n  Causal Million-Length Sequence Modeling",
    "authors": "Eric Egli, Matteo Manica, Jannis Born",
    "summary": "Bytes form the basis of the digital world and thus are a promising building\nblock for multimodal foundation models. Recently, Byte Language Models (BLMs)\nhave emerged to overcome tokenization, yet the excessive length of bytestreams\nrequires new architectural paradigms. Therefore, we present the Multiscale Byte\nLanguage Model (MBLM), a model-agnostic hierarchical decoder stack that allows\ntraining with context windows of $5$M bytes on single GPU in full model\nprecision. We thoroughly examine MBLM's performance with Transformer and Mamba\nblocks on both unimodal and multimodal tasks. Our experiments demonstrate that\nhybrid architectures are efficient in handling extremely long byte sequences\nduring training while achieving near-linear generational efficiency. To the\nbest of our knowledge, we present the first evaluation of BLMs on visual Q\\&A\ntasks and find that, despite serializing images and the absence of an encoder,\na MBLM with pure next token prediction can match custom CNN-LSTM architectures\nwith designated classification heads. We show that MBLMs exhibit strong\nadaptability in integrating diverse data representations, including pixel and\nimage filestream bytes, underlining their potential toward omnimodal foundation\nmodels. Source code is publicly available at:\nhttps://github.com/ai4sd/multiscale-byte-lm",
    "published": "2025-02-20T13:31:50Z",
    "pdf_link": "http://arxiv.org/pdf/2502.14553v1"
  },
  {
    "title": "Small Graph Is All You Need: DeepStateGNN for Scalable Traffic\n  Forecasting",
    "authors": "Yannick W\u00f6lker, Arash Hajisafi, Cyrus Shahabi, Matthias Renz",
    "summary": "We propose a novel Graph Neural Network (GNN) model, named DeepStateGNN, for\nanalyzing traffic data, demonstrating its efficacy in two critical tasks:\nforecasting and reconstruction. Unlike typical GNN methods that treat each\ntraffic sensor as an individual graph node, DeepStateGNN clusters sensors into\nhigher-level graph nodes, dubbed Deep State Nodes, based on various similarity\ncriteria, resulting in a fixed number of nodes in a Deep State graph. The term\n\"Deep State\" nodes is a play on words, referencing hidden networks of power\nthat, like these nodes, secretly govern traffic independently of visible\nsensors. These Deep State Nodes are defined by several similarity factors,\nincluding spatial proximity (e.g., sensors located nearby in the road network),\nfunctional similarity (e.g., sensors on similar types of freeways), and\nbehavioral similarity under specific conditions (e.g., traffic behavior during\nrain). This clustering approach allows for dynamic and adaptive node grouping,\nas sensors can belong to multiple clusters and clusters may evolve over time.\nOur experimental results show that DeepStateGNN offers superior scalability and\nfaster training, while also delivering more accurate results than competitors.\nIt effectively handles large-scale sensor networks, outperforming other methods\nin both traffic forecasting and reconstruction accuracy.",
    "published": "2025-02-20T13:00:31Z",
    "pdf_link": "http://arxiv.org/pdf/2502.14525v1"
  },
  {
    "title": "Stories that (are) Move(d by) Markets: A Causal Exploration of Market\n  Shocks and Semantic Shifts across Different Partisan Groups",
    "authors": "Felix Drinkall, Stefan Zohren, Michael McMahon, Janet B. Pierrehumbert",
    "summary": "Macroeconomic fluctuations and the narratives that shape them form a mutually\nreinforcing cycle: public discourse can spur behavioural changes leading to\neconomic shifts, which then result in changes in the stories that propagate. We\nshow that shifts in semantic embedding space can be causally linked to\nfinancial market shocks -- deviations from the expected market behaviour.\nFurthermore, we show how partisanship can influence the predictive power of\ntext for market fluctuations and shape reactions to those same shocks. We also\nprovide some evidence that text-based signals are particularly salient during\nunexpected events such as COVID-19, highlighting the value of language data as\nan exogenous variable in economic forecasting. Our findings underscore the\nbidirectional relationship between news outlets and market shocks, offering a\nnovel empirical approach to studying their effect on each other.",
    "published": "2025-02-20T12:26:56Z",
    "pdf_link": "http://arxiv.org/pdf/2502.14497v1"
  },
  {
    "title": "Statistical Scenario Modelling and Lookalike Distributions for\n  Multi-Variate AI Risk",
    "authors": "Elija Perrier",
    "summary": "Evaluating AI safety requires statistically rigorous methods and risk metrics\nfor understanding how the use of AI affects aggregated risk. However, much AI\nsafety literature focuses upon risks arising from AI models in isolation,\nlacking consideration of how modular use of AI affects risk distribution of\nworkflow components or overall risk metrics. There is also a lack of\nstatistical grounding enabling sensitisation of risk models in the presence of\nabsence of AI to estimate causal contributions of AI. This is in part due to\nthe dearth of AI impact data upon which to fit distributions. In this work, we\naddress these gaps in two ways. First, we demonstrate how scenario modelling\n(grounded in established statistical techniques such as Markov chains, copulas\nand Monte Carlo simulation) can be used to model AI risk holistically. Second,\nwe show how lookalike distributions from phenomena analogous to AI can be used\nto estimate AI impacts in the absence of directly observable data. We\ndemonstrate the utility of our methods for benchmarking cumulative AI risk via\nrisk analysis of a logistic scenario simulations.",
    "published": "2025-02-20T12:14:54Z",
    "pdf_link": "http://arxiv.org/pdf/2502.14491v1"
  }
]