[
  {
    "title": "Difference-in-Differences and Changes-in-Changes with Sample Selection",
    "authors": "Javier Viviens",
    "summary": "Sample selection arises endogenously in causal research when the treatment\naffects whether certain units are observed. It is a common pitfall in\nlongitudinal studies, particularly in settings where treatment assignment is\nconfounded. In this paper, I highlight the drawbacks of one of the most popular\nidentification strategies in such settings: Difference-in-Differences (DiD).\nSpecifically, I employ principal stratification analysis to show that the\nconventional ATT estimand may not be well defined, and the DiD estimand cannot\nbe interpreted causally without additional assumptions. To address these\nissues, I develop an identification strategy to partially identify causal\neffects on the subset of units with well-defined and observed outcomes under\nboth treatment regimes. I adapt Lee bounds to the Changes-in-Changes (CiC)\nsetting (Athey & Imbens, 2006), leveraging the time dimension of the data to\nrelax the unconfoundedness assumption in the original trimming strategy of Lee\n(2009). This setting has the DiD identification strategy as a particular case,\nwhich I also implement in the paper. Additionally, I explore how to leverage\nmultiple sources of sample selection to relax the monotonicity assumption in\nLee (2009), which may be of independent interest. Alongside the identification\nstrategy, I present estimators and inference results. I illustrate the\nrelevance of the proposed methodology by analyzing a job training program in\nColombia.",
    "published": "2025-02-12T18:03:11Z",
    "pdf_link": "http://arxiv.org/pdf/2502.08614v1"
  },
  {
    "title": "Toward Universal Laws of Outlier Propagation",
    "authors": "Yuhao Wang, Aram Ebtekar, Dominik Janzing",
    "summary": "We argue that Algorithmic Information Theory (AIT) admits a principled way to\nquantify outliers in terms of so-called randomness deficiency. For the\nprobability distribution generated by a causal Bayesian network, we show that\nthe randomness deficiency of the joint state decomposes into randomness\ndeficiencies of each causal mechanism, subject to the Independence of\nMechanisms Principle. Accordingly, anomalous joint observations can be\nquantitatively attributed to their root causes, i.e., the mechanisms that\nbehaved anomalously. As an extension of Levin's law of randomness conservation,\nwe show that weak outliers cannot cause strong ones when Independence of\nMechanisms holds. We show how these information theoretic laws provide a better\nunderstanding of the behaviour of outliers defined with respect to existing\nscores.",
    "published": "2025-02-12T17:32:23Z",
    "pdf_link": "http://arxiv.org/pdf/2502.08593v1"
  },
  {
    "title": "Causal Analysis of ASR Errors for Children: Quantifying the Impact of\n  Physiological, Cognitive, and Extrinsic Factors",
    "authors": "Vishwanath Pratap Singh, Md. Sahidullah, Tomi Kinnunen",
    "summary": "The increasing use of children's automatic speech recognition (ASR) systems\nhas spurred research efforts to improve the accuracy of models designed for\nchildren's speech in recent years. The current approach utilizes either\nopen-source speech foundation models (SFMs) directly or fine-tuning them with\nchildren's speech data. These SFMs, whether open-source or fine-tuned for\nchildren, often exhibit higher word error rates (WERs) compared to adult\nspeech. However, there is a lack of systemic analysis of the cause of this\ndegraded performance of SFMs. Understanding and addressing the reasons behind\nthis performance disparity is crucial for improving the accuracy of SFMs for\nchildren's speech. Our study addresses this gap by investigating the causes of\naccuracy degradation and the primary contributors to WER in children's speech.\nIn the first part of the study, we conduct a comprehensive benchmarking study\non two self-supervised SFMs (Wav2Vec2.0 and Hubert) and two weakly supervised\nSFMs (Whisper and MMS) across various age groups on two children speech\ncorpora, establishing the raw data for the causal inference analysis in the\nsecond part. In the second part of the study, we analyze the impact of\nphysiological factors (age, gender), cognitive factors (pronunciation ability),\nand external factors (vocabulary difficulty, background noise, and word count)\non SFM accuracy in children's speech using causal inference. The results\nindicate that physiology (age) and particular external factor (number of words\nin audio) have the highest impact on accuracy, followed by background noise and\npronunciation ability. Fine-tuning SFMs on children's speech reduces\nsensitivity to physiological and cognitive factors, while sensitivity to the\nnumber of words in audio persists.\n  Keywords: Children's ASR, Speech Foundational Models, Causal Inference,\nPhysiology, Cognition, Pronunciation",
    "published": "2025-02-12T17:20:37Z",
    "pdf_link": "http://arxiv.org/pdf/2502.08587v1"
  },
  {
    "title": "Bridging time across null horizons",
    "authors": "An\u0131l Zengino\u011flu",
    "summary": "General relativity, as a diffeomorphism-invariant theory, allows the\ndescription of physical phenomena in a wide variety of coordinate systems. In\nthe presence of boundaries, such as event horizons and null infinity, time\ncoordinates must be carefully adapted to the global causal structure of\nspacetime to ensure a computationally efficient description.\nHorizon-penetrating time is used to describe the dynamics of infalling matter\nand radiation across the event horizon, while hyperboloidal time is used to\nstudy the propagation of radiation toward the idealized observer at null\ninfinity.\n  In this paper, we explore the historical and mathematical connection between\nhorizon-penetrating and hyperboloidal time coordinates, arguing that both\nclasses of coordinates are simply regular choices of time across null horizons.\nWe review the height-function formalism in stationary spacetimes, providing\nexamples that may be useful in computations, such as source-adapted foliations\nor Fefferman-Graham-Bondi coordinates near null infinity. We discuss bridges\nconnecting the boundaries of spacetime through a time hypersurface across null\nhorizons, including the event horizon, null infinity, and the cosmological\nhorizon.\n  This work is motivated by the broader effort to understand the role of time\nin general relativity and reviews a unified framework for handling null\nboundaries in analytical and numerical approaches. The insights developed here\noffer practical tools for numerical relativity, gravitational wave astronomy,\nand other explorations of the large-scale structure of spacetimes.",
    "published": "2025-02-12T17:12:23Z",
    "pdf_link": "http://arxiv.org/pdf/2502.08581v1"
  },
  {
    "title": "COAST: Intelligent Time-Adaptive Neural Operators",
    "authors": "Zhikai Wu, Shiyang Zhang, Sizhuang He, Sifan Wang, Min Zhu, Anran Jiao, Lu Lu, David van Dijk",
    "summary": "We introduce Causal Operator with Adaptive Solver Transformer (COAST), a\nnovel neural operator learning method that leverages a causal language model\n(CLM) framework to dynamically adapt time steps. Our method predicts both the\nevolution of a system and its optimal time step, intelligently balancing\ncomputational efficiency and accuracy. We find that COAST generates variable\nstep sizes that correlate with the underlying system intrinsicities, both\nwithin and across dynamical systems. Within a single trajectory, smaller steps\nare taken in regions of high complexity, while larger steps are employed in\nsimpler regions. Across different systems, more complex dynamics receive more\ngranular time steps. Benchmarked on diverse systems with varied dynamics, COAST\nconsistently outperforms state-of-the-art methods, achieving superior\nperformance in both efficiency and accuracy. This work underscores the\npotential of CLM-based intelligent adaptive solvers for scalable operator\nlearning of dynamical systems.",
    "published": "2025-02-12T17:09:13Z",
    "pdf_link": "http://arxiv.org/pdf/2502.08574v1"
  },
  {
    "title": "Anytime-valid FDR control with the stopped e-BH procedure",
    "authors": "Hongjian Wang, Sanjit Dandapanthula, Aaditya Ramdas",
    "summary": "The recent e-Benjamini-Hochberg (e-BH) procedure for multiple hypothesis\ntesting is known to control the false discovery rate (FDR) under arbitrary\ndependence between the input e-values. This paper points out an important\nsubtlety when applying the e-BH procedure with e-processes, which are\nsequential generalizations of e-values (where the data are observed\nsequentially). Since adaptively stopped e-processes are e-values, the e-BH\nprocedure can be repeatedly applied at every time step, and one can\ncontinuously monitor the e-processes and the rejection sets obtained. One would\nhope that the \"stopped e-BH procedure\" (se-BH) has an FDR guarantee for the\nrejection set obtained at any stopping time. However, while this is true if the\ndata in different streams are independent, it is not true in full generality,\nbecause each stopped e-process is an e-value only for stopping times in its own\nlocal filtration, but the se-BH procedure employs a stopping time with respect\nto a global filtration. This can cause information to leak across time,\nallowing one stream to know its future by knowing past data of another stream.\nThis paper formulates a simple causal condition under which local e-processes\nare also global e-processes and thus the se-BH procedure does indeed control\nthe FDR. The condition excludes unobserved confounding from the past and is met\nunder most reasonable scenarios including genomics.",
    "published": "2025-02-12T16:23:44Z",
    "pdf_link": "http://arxiv.org/pdf/2502.08539v1"
  },
  {
    "title": "Bridging Domain Adaptation and Graph Neural Networks: A Tensor-Based\n  Framework for Effective Label Propagation",
    "authors": "Tao Wen, Elynn Chen, Yuzhou Chen, Qi Lei",
    "summary": "Graph Neural Networks (GNNs) have recently become the predominant tools for\nstudying graph data. Despite state-of-the-art performance on graph\nclassification tasks, GNNs are overwhelmingly trained in a single domain under\nsupervision, thus necessitating a prohibitively high demand for labels and\nresulting in poorly transferable representations. To address this challenge, we\npropose the Label-Propagation Tensor Graph Neural Network (LP-TGNN) framework\nto bridge the gap between graph data and traditional domain adaptation methods.\nIt extracts graph topological information holistically with a tensor\narchitecture and then reduces domain discrepancy through label propagation. It\nis readily compatible with general GNNs and domain adaptation techniques with\nminimal adjustment through pseudo-labeling. Experiments on various real-world\nbenchmarks show that our LP-TGNN outperforms baselines by a notable margin. We\nalso validate and analyze each component of the proposed framework in the\nablation study.",
    "published": "2025-02-12T15:36:38Z",
    "pdf_link": "http://arxiv.org/pdf/2502.08505v1"
  },
  {
    "title": "Foundations of Digital Circuits: Denotation, Operational, and Algebraic\n  Semantics",
    "authors": "George Kaye",
    "summary": "This thesis details a project to define a fully compositional theory of\nsynchronous sequential circuits built from primitive components, motivated by\napplying techniques successfully used in programming languages to hardware.\n  The first part of the thesis defines the syntactic foundations of sequential\ncircuit morphisms, and then builds three different semantic theories:\ndenotational, operational and algebraic. We characterise the denotational\nsemantics of sequential circuits as certain causal stream functions, as well as\nproviding a link to existing circuit methodologies by mapping between circuit\nmorphisms, stream functions and Mealy machines. The operational semantics is\ndefined as a strategy for applying some global transformations followed by\nlocal reductions to demonstrate how a circuit processes a value, leading to a\nnotion of observational equivalence. The algebraic semantics consists of\nequations for bringing circuits into a pseudo-normal form, and then encoding\nbetween different state sets. This part of the thesis concludes with a\ndiscussion of some novel applications, such as those for using partial\nevaluation for digital circuits.\n  While mathematically rigorous, the categorical string diagram formalism is\nnot suited for reasoning computationally. The second part of this thesis\ndetails an extension of string diagram rewriting with hypergraphs so that it is\ncompatible with the traced comonoid structure present in the category of\ndigital circuits. We identify the properties that characterise cospans of\nhypergraphs corresponding to traced comonoid terms, and demonstrate how to\nidentify rewriting contexts valid for rewriting modulo traced comonoid\nstructure. We apply the graph rewriting framework to fixed point operators as\nwell as the operational semantics from the first part, and present a new\nhardware description language based on these theoretical developments.",
    "published": "2025-02-12T15:32:52Z",
    "pdf_link": "http://arxiv.org/pdf/2502.08497v1"
  },
  {
    "title": "Tutorial for Surrogate Endpoint Validation Using Joint modeling and\n  Mediation Analysis",
    "authors": "Quentin Le Coent, Virginie Rondeau, Catherine Legrand",
    "summary": "The use of valid surrogate endpoints is an important stake in clinical\nresearch to help reduce both the duration and cost of a clinical trial and\nspeed up the evaluation of interesting treatments. Several methods have been\nproposed in the statistical literature to validate putative surrogate\nendpoints. Two main approaches have been proposed: the meta-analytic approach\nand the mediation analysis approach. The former uses data from meta-analyses to\nderive associations measures between the surrogate and the final endpoint at\nthe individual and trial levels. The latter rather uses the proportion of the\ntreatment effect on the final endpoint through the surrogate as a measure of\nsurrogacy in a causal inference framework. Both approaches have remained\nseparated as the meta-analytic approach does not estimate the treatment effect\non the final endpoint through the surrogate while the mediation analysis\napproach have been limited to single-trial setting. However, these two\napproaches are complementary. In this work we propose an approach that combines\nthe meta-analytic and mediation analysis approaches using joint modeling for\nsurrogate validation. We focus on the cases where the final endpoint is a\ntime-to-event endpoint (such as time-to-death) and the surrogate is either a\ntime-to-event or a longitudinal biomarker. Two new joint models were proposed\ndepending on the nature of the surrogate. These model are implemented in the R\npackage frailtypack. We illustrate the developed approaches in three\napplications on real datasets in oncology.",
    "published": "2025-02-12T14:34:04Z",
    "pdf_link": "http://arxiv.org/pdf/2502.08443v1"
  },
  {
    "title": "Trustworthy GNNs with LLMs: A Systematic Review and Taxonomy",
    "authors": "Ruizhan Xue, Huimin Deng, Fang He, Maojun Wang, Zeyu Zhang",
    "summary": "With the extensive application of Graph Neural Networks (GNNs) across various\ndomains, their trustworthiness has emerged as a focal point of research. Some\nexisting studies have shown that the integration of large language models\n(LLMs) can improve the semantic understanding and generation capabilities of\nGNNs, which in turn improves the trustworthiness of GNNs from various aspects.\nOur review introduces a taxonomy that offers researchers a clear framework for\ncomprehending the principles and applications of different methods and helps\nclarify the connections and differences among various approaches. Then we\nsystematically survey representative approaches along the four categories of\nour taxonomy. Through our taxonomy, researchers can understand the applicable\nscenarios, potential advantages, and limitations of each approach for the the\ntrusted integration of GNNs with LLMs. Finally, we present some promising\ndirections of work and future trends for the integration of LLMs and GNNs to\nimprove model trustworthiness.",
    "published": "2025-02-12T12:28:39Z",
    "pdf_link": "http://arxiv.org/pdf/2502.08353v1"
  }
]