[
  {
    "title": "A unique coupling of the massive spin-2 field to supergravity",
    "authors": "Guillaume Bossard, Gabriele Casagrande, Emilian Dudas, Adrien Loty",
    "summary": "We show that the coupling of a massive spin-2 field to undeformed N=1\nsupergravity in four dimensions is unique, leading to a specific non-minimal\ncoupling to the Riemann tensor. The massive spin-2 coupling reproduces the one\nof an oscillator mode in open string theory, while the massive spin-1 coupling\nincludes a higher-derivative term that is expected to violate causality in the\nbackground of a gravitational shock wave. We argue that the resolution of\ncausality and the unitarity bound in the Regge limit require the introduction\nof infinitely many higher-spin fields similar to the Regge trajectories in\nstring theory, therefore providing an argument in favour of the string lamppost\nprinciple with minimal supersymmetry in four dimensions. To obtain this result,\nwe construct the general stress-energy tensor multiplet for the massive spin-2\nmultiplet with N=1 supersymmetry.",
    "published": "2025-02-13T18:52:18Z",
    "pdf_link": "http://arxiv.org/pdf/2502.09599v1"
  },
  {
    "title": "Enhancing the Utility of Higher-Order Information in Relational Learning",
    "authors": "Raphael Pellegrin, Lukas Fesser, Melanie Weber",
    "summary": "Higher-order information is crucial for relational learning in many domains\nwhere relationships extend beyond pairwise interactions. Hypergraphs provide a\nnatural framework for modeling such relationships, which has motivated recent\nextensions of graph neural net- work architectures to hypergraphs. However,\ncomparisons between hypergraph architectures and standard graph-level models\nremain limited. In this work, we systematically evaluate a selection of\nhypergraph-level and graph-level architectures, to determine their\neffectiveness in leveraging higher-order information in relational learning.\nOur results show that graph-level architectures applied to hypergraph\nexpansions often outperform hypergraph- level ones, even on inputs that are\nnaturally parametrized as hypergraphs. As an alternative approach for\nleveraging higher-order information, we propose hypergraph-level encodings\nbased on classical hypergraph characteristics. While these encodings do not\nsignificantly improve hypergraph architectures, they yield substantial\nperformance gains when combined with graph-level models. Our theoretical\nanalysis shows that hypergraph-level encodings provably increase the\nrepresentational power of message-passing graph neural networks beyond that of\ntheir graph-level counterparts.",
    "published": "2025-02-13T18:28:17Z",
    "pdf_link": "http://arxiv.org/pdf/2502.09570v1"
  },
  {
    "title": "Long-Term TalkingFace Generation via Motion-Prior Conditional Diffusion\n  Model",
    "authors": "Fei Shen, Cong Wang, Junyao Gao, Qin Guo, Jisheng Dang, Jinhui Tang, Tat-Seng Chua",
    "summary": "Recent advances in conditional diffusion models have shown promise for\ngenerating realistic TalkingFace videos, yet challenges persist in achieving\nconsistent head movement, synchronized facial expressions, and accurate lip\nsynchronization over extended generations. To address these, we introduce the\n\\textbf{M}otion-priors \\textbf{C}onditional \\textbf{D}iffusion \\textbf{M}odel\n(\\textbf{MCDM}), which utilizes both archived and current clip motion priors to\nenhance motion prediction and ensure temporal consistency. The model consists\nof three key elements: (1) an archived-clip motion-prior that incorporates\nhistorical frames and a reference frame to preserve identity and context; (2) a\npresent-clip motion-prior diffusion model that captures multimodal causality\nfor accurate predictions of head movements, lip sync, and expressions; and (3)\na memory-efficient temporal attention mechanism that mitigates error\naccumulation by dynamically storing and updating motion features. We also\nrelease the \\textbf{TalkingFace-Wild} dataset, a multilingual collection of\nover 200 hours of footage across 10 languages. Experimental results demonstrate\nthe effectiveness of MCDM in maintaining identity and motion continuity for\nlong-term TalkingFace generation. Code, models, and datasets will be publicly\navailable.",
    "published": "2025-02-13T17:50:23Z",
    "pdf_link": "http://arxiv.org/pdf/2502.09533v1"
  },
  {
    "title": "Just Trial Once: Ongoing Causal Validation of Machine Learning Models",
    "authors": "Jacob M. Chen, Michael Oberst",
    "summary": "Machine learning (ML) models are increasingly used as decision-support tools\nin high-risk domains. Evaluating the causal impact of deploying such models can\nbe done with a randomized controlled trial (RCT) that randomizes users to ML\nvs. control groups and assesses the effect on relevant outcomes. However, ML\nmodels are inevitably updated over time, and we often lack evidence for the\ncausal impact of these updates. While the causal effect could be repeatedly\nvalidated with ongoing RCTs, such experiments are expensive and time-consuming\nto run. In this work, we present an alternative solution: using only data from\na prior RCT, we give conditions under which the causal impact of a new ML model\ncan be precisely bounded or estimated, even if it was not included in the RCT.\nOur assumptions incorporate two realistic constraints: ML predictions are often\ndeterministic, and their impacts depend on user trust in the model. Based on\nour analysis, we give recommendations for trial designs that maximize our\nability to assess future versions of an ML model. Our hope is that our trial\ndesign recommendations will save practitioners time and resources while\nallowing for quicker deployments of updates to ML models.",
    "published": "2025-02-13T16:31:50Z",
    "pdf_link": "http://arxiv.org/pdf/2502.09467v1"
  },
  {
    "title": "Robot Pouring: Identifying Causes of Spillage and Selecting Alternative\n  Action Parameters Using Probabilistic Actual Causation",
    "authors": "Jaime Maldonado, Jonas Krumme, Christoph Zetzsche, Vanessa Didelez, Kerstin Schill",
    "summary": "In everyday life, we perform tasks (e.g., cooking or cleaning) that involve a\nlarge variety of objects and goals. When confronted with an unexpected or\nunwanted outcome, we take corrective actions and try again until achieving the\ndesired result. The reasoning performed to identify a cause of the observed\noutcome and to select an appropriate corrective action is a crucial aspect of\nhuman reasoning for successful task execution. Central to this reasoning is the\nassumption that a factor is responsible for producing the observed outcome. In\nthis paper, we investigate the use of probabilistic actual causation to\ndetermine whether a factor is the cause of an observed undesired outcome.\nFurthermore, we show how the actual causation probabilities can be used to find\nalternative actions to change the outcome. We apply the probabilistic actual\ncausation analysis to a robot pouring task. When spillage occurs, the analysis\nindicates whether a task parameter is the cause and how it should be changed to\navoid spillage. The analysis requires a causal graph of the task and the\ncorresponding conditional probability distributions. To fulfill these\nrequirements, we perform a complete causal modeling procedure (i.e., task\nanalysis, definition of variables, determination of the causal graph structure,\nand estimation of conditional probability distributions) using data from a\nrealistic simulation of the robot pouring task, covering a large combinatorial\nspace of task parameters. Based on the results, we discuss the implications of\nthe variables' representation and how the alternative actions suggested by the\nactual causation analysis would compare to the alternative solutions proposed\nby a human observer. The practical use of the analysis of probabilistic actual\ncausation to select alternative action parameters is demonstrated.",
    "published": "2025-02-13T15:16:52Z",
    "pdf_link": "http://arxiv.org/pdf/2502.09395v1"
  },
  {
    "title": "Optimal Microcontroller Usage in Reconfigurable Intelligent Surface:\n  Batteryless IoT Systems Case Study",
    "authors": "Shakil Ahmed, Ahmed E. Kamal, Mohamed Y. Selim",
    "summary": "To enhance wireless communication in IoT systems using reconfigurable\nintelligent surfaces (RISs), efficient control of programmable passive and\nactive elements is essential. However, increasing RIS elements requires more\nmicrocontrollers, raising complexity and cost. This paper proposes a modular\napproach (\"Module\"), where each microcontroller controls a module of optimal\nactive or passive elements. The module size is determined using a non-linear\nenergy harvesting model, where a batteryless IoT (b-IoT) sensor harvests energy\nfrom base station (BS) RF signals. We optimize the number of modules\n(microcontrollers) to minimize energy consumption while satisfying energy\nharvesting and information causality constraints. Simulations show that RIS\nmodule-assisted energy harvesting improves IoT system performance by ~100%\ncompared to models without RIS panels.",
    "published": "2025-02-13T14:35:15Z",
    "pdf_link": "http://arxiv.org/pdf/2502.09368v1"
  },
  {
    "title": "Machine learning for modelling unstructured grid data in computational\n  physics: a review",
    "authors": "Sibo Cheng, Marc Bocquet, Weiping Ding, Tobias Sebastian Finn, Rui Fu, Jinlong Fu, Yike Guo, Eleda Johnson, Siyi Li, Che Liu, Eric Newton Moro, Jie Pan, Matthew Piggott, Cesar Quilodran, Prakhar Sharma, Kun Wang, Dunhui Xiao, Xiao Xue, Yong Zeng, Mingrui Zhang, Hao Zhou, Kewei Zhu, Rossella Arcucci",
    "summary": "Unstructured grid data are essential for modelling complex geometries and\ndynamics in computational physics. Yet, their inherent irregularity presents\nsignificant challenges for conventional machine learning (ML) techniques. This\npaper provides a comprehensive review of advanced ML methodologies designed to\nhandle unstructured grid data in high-dimensional dynamical systems. Key\napproaches discussed include graph neural networks, transformer models with\nspatial attention mechanisms, interpolation-integrated ML methods, and meshless\ntechniques such as physics-informed neural networks. These methodologies have\nproven effective across diverse fields, including fluid dynamics and\nenvironmental simulations. This review is intended as a guidebook for\ncomputational scientists seeking to apply ML approaches to unstructured grid\ndata in their domains, as well as for ML researchers looking to address\nchallenges in computational physics. It places special focus on how ML methods\ncan overcome the inherent limitations of traditional numerical techniques and,\nconversely, how insights from computational physics can inform ML development.\nTo support benchmarking, this review also provides a summary of open-access\ndatasets of unstructured grid data in computational physics. Finally, emerging\ndirections such as generative models with unstructured data, reinforcement\nlearning for mesh generation, and hybrid physics-data-driven paradigms are\ndiscussed to inspire future advancements in this evolving field.",
    "published": "2025-02-13T14:11:33Z",
    "pdf_link": "http://arxiv.org/pdf/2502.09346v1"
  },
  {
    "title": "Revisiting Topological Interference Management: A Learning-to-Code on\n  Graphs Perspective",
    "authors": "Zhiwei Shan, Xinping Yi, Han Yu, Chung-Shou Liao, Shi Jin",
    "summary": "The advance of topological interference management (TIM) has been one of the\ndriving forces of recent developments in network information theory. However,\nstate-of-the-art coding schemes for TIM are usually handcrafted for specific\nfamilies of network topologies, relying critically on experts' domain knowledge\nand sophisticated treatments. The lack of systematic and automatic generation\nof solutions inevitably restricts their potential wider applications to\nwireless communication systems, due to the limited generalizability of coding\nschemes to wider network configurations. To address such an issue, this work\nmakes the first attempt to advocate revisiting topological interference\nalignment (IA) from a novel learning-to-code perspective. Specifically, we\nrecast the one-to-one and subspace IA conditions as vector assignment policies\nand propose a unifying learning-to-code on graphs (LCG) framework by leveraging\ngraph neural networks (GNNs) for capturing topological structures and\nreinforcement learning (RL) for decision-making of IA beamforming vector\nassignment. Interestingly, the proposed LCG framework is capable of recovering\nknown one-to-one scalar/vector IA solutions for a significantly wider range of\nnetwork topologies, and more remarkably of discovering new subspace IA coding\nschemes for multiple-antenna cases that are challenging to be handcrafted. The\nextensive experiments demonstrate that the LCG framework is an effective way to\nautomatically produce systematic coding solutions to the TIM instances with\narbitrary network topologies, and at the same time, the underlying learning\nalgorithm is efficient with respect to online inference time and possesses\nexcellent generalizability and transferability for practical deployment.",
    "published": "2025-02-13T14:07:51Z",
    "pdf_link": "http://arxiv.org/pdf/2502.09344v1"
  },
  {
    "title": "Graph Diffusion Network for Drug-Gene Prediction",
    "authors": "Jiayang Wu, Wensheng Gan, Philip S. Yu",
    "summary": "Predicting drug-gene associations is crucial for drug development and disease\ntreatment. While graph neural networks (GNN) have shown effectiveness in this\ntask, they face challenges with data sparsity and efficient contrastive\nlearning implementation. We introduce a graph diffusion network for drug-gene\nprediction (GDNDGP), a framework that addresses these limitations through two\nkey innovations. First, it employs meta-path-based homogeneous graph learning\nto capture drug-drug and gene-gene relationships, ensuring similar entities\nshare embedding spaces. Second, it incorporates a parallel diffusion network\nthat generates hard negative samples during training, eliminating the need for\nexhaustive negative sample retrieval. Our model achieves superior performance\non the DGIdb 4.0 dataset and demonstrates strong generalization capability on\ntripartite drug-gene-disease networks. Results show significant improvements\nover existing methods in drug-gene prediction tasks, particularly in handling\ncomplex heterogeneous relationships. The source code is publicly available at\nhttps://github.com/csjywu1/GDNDGP.",
    "published": "2025-02-13T13:54:58Z",
    "pdf_link": "http://arxiv.org/pdf/2502.09335v1"
  },
  {
    "title": "Feedback control solves pseudoconvex optimal tracking problems in\n  nonlinear dynamical systems",
    "authors": "Tingli Hu, Sami Haddadin",
    "summary": "Achieving optimality in controlling physical systems is a profound challenge\nacross diverse scientific and engineering fields, spanning neuromechanics,\nbiochemistry, autonomous systems, economics, and beyond. Traditional solutions,\nrelying on time-consuming offline iterative algorithms, often yield limited\ninsights into fundamental natural processes. In this work, we introduce a\nnovel, causally deterministic approach, presenting the closed-form optimal\ntracking controller (OTC) that inherently solves pseudoconvex optimization\nproblems in various fields. Through rigorous analysis and comprehensive\nnumerical examples, we demonstrate OTC's capability of achieving both high\naccuracy and rapid response, even when facing high-dimensional and\nhigh-dynamical real-world problems. Notably, our OTC outperforms\nstate-of-the-art methods by, e.g., solving a 1304-dimensional neuromechanics\nproblem 1311 times faster or with 113 times higher accuracy. Most importantly,\nOTC embodies a causally deterministic system interpretation of optimality\nprinciples, providing a new and fundamental perspective of optimization in\nnatural and artificial processes. We anticipate our work to be an important\nstep towards establishing a general causally deterministic optimization theory\nfor a broader spectrum of system and problem classes, promising advances in\nunderstanding optimality principles in complex systems.",
    "published": "2025-02-13T13:37:00Z",
    "pdf_link": "http://arxiv.org/pdf/2502.09322v1"
  }
]