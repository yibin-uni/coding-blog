[
  {
    "title": "RAD: Training an End-to-End Driving Policy via Large-Scale 3DGS-based\n  Reinforcement Learning",
    "authors": "Hao Gao, Shaoyu Chen, Bo Jiang, Bencheng Liao, Yiang Shi, Xiaoyang Guo, Yuechuan Pu, Haoran Yin, Xiangyu Li, Xinbang Zhang, Ying Zhang, Wenyu Liu, Qian Zhang, Xinggang Wang",
    "summary": "Existing end-to-end autonomous driving (AD) algorithms typically follow the\nImitation Learning (IL) paradigm, which faces challenges such as causal\nconfusion and the open-loop gap. In this work, we establish a 3DGS-based\nclosed-loop Reinforcement Learning (RL) training paradigm. By leveraging 3DGS\ntechniques, we construct a photorealistic digital replica of the real physical\nworld, enabling the AD policy to extensively explore the state space and learn\nto handle out-of-distribution scenarios through large-scale trial and error. To\nenhance safety, we design specialized rewards that guide the policy to\neffectively respond to safety-critical events and understand real-world causal\nrelationships. For better alignment with human driving behavior, IL is\nincorporated into RL training as a regularization term. We introduce a\nclosed-loop evaluation benchmark consisting of diverse, previously unseen 3DGS\nenvironments. Compared to IL-based methods, RAD achieves stronger performance\nin most closed-loop metrics, especially 3x lower collision rate. Abundant\nclosed-loop results are presented at https://hgao-cv.github.io/RAD.",
    "published": "2025-02-18T18:59:21Z",
    "pdf_link": "http://arxiv.org/pdf/2502.13144v1"
  },
  {
    "title": "Learning to Defer for Causal Discovery with Imperfect Experts",
    "authors": "Oscar Clivio, Divyat Mahajan, Perouz Taslakian, Sara Magliacane, Ioannis Mitliagkas, Valentina Zantedeschi, Alexandre Drouin",
    "summary": "Integrating expert knowledge, e.g. from large language models, into causal\ndiscovery algorithms can be challenging when the knowledge is not guaranteed to\nbe correct. Expert recommendations may contradict data-driven results, and\ntheir reliability can vary significantly depending on the domain or specific\nquery. Existing methods based on soft constraints or inconsistencies in\npredicted causal relationships fail to account for these variations in\nexpertise. To remedy this, we propose L2D-CD, a method for gauging the\ncorrectness of expert recommendations and optimally combining them with\ndata-driven causal discovery results. By adapting learning-to-defer (L2D)\nalgorithms for pairwise causal discovery (CD), we learn a deferral function\nthat selects whether to rely on classical causal discovery methods using\nnumerical data or expert recommendations based on textual meta-data. We\nevaluate L2D-CD on the canonical T\\\"ubingen pairs dataset and demonstrate its\nsuperior performance compared to both the causal discovery method and the\nexpert used in isolation. Moreover, our approach identifies domains where the\nexpert's performance is strong or weak. Finally, we outline a strategy for\ngeneralizing this approach to causal discovery on graphs with more than two\nvariables, paving the way for further research in this area.",
    "published": "2025-02-18T18:55:53Z",
    "pdf_link": "http://arxiv.org/pdf/2502.13132v1"
  },
  {
    "title": "Efficient and Sharp Off-Policy Learning under Unobserved Confounding",
    "authors": "Konstantin Hess, Dennis Frauen, Valentyn Melnychuk, Stefan Feuerriegel",
    "summary": "We develop a novel method for personalized off-policy learning in scenarios\nwith unobserved confounding. Thereby, we address a key limitation of standard\npolicy learning: standard policy learning assumes unconfoundedness, meaning\nthat no unobserved factors influence both treatment assignment and outcomes.\nHowever, this assumption is often violated, because of which standard policy\nlearning produces biased estimates and thus leads to policies that can be\nharmful. To address this limitation, we employ causal sensitivity analysis and\nderive a statistically efficient estimator for a sharp bound on the value\nfunction under unobserved confounding. Our estimator has three advantages: (1)\nUnlike existing works, our estimator avoids unstable minimax optimization based\non inverse propensity weighted outcomes. (2) Our estimator is statistically\nefficient. (3) We prove that our estimator leads to the optimal\nconfounding-robust policy. Finally, we extend our theory to the related task of\npolicy improvement under unobserved confounding, i.e., when a baseline policy\nsuch as the standard of care is available. We show in experiments with\nsynthetic and real-world data that our method outperforms simple plug-in\napproaches and existing baselines. Our method is highly relevant for\ndecision-making where unobserved confounding can be problematic, such as in\nhealthcare and public policy.",
    "published": "2025-02-18T16:42:24Z",
    "pdf_link": "http://arxiv.org/pdf/2502.13022v1"
  },
  {
    "title": "Tuning Algorithmic and Architectural Hyperparameters in Graph-Based\n  Semi-Supervised Learning with Provable Guarantees",
    "authors": "Ally Yalei Du, Eric Huang, Dravyansh Sharma",
    "summary": "Graph-based semi-supervised learning is a powerful paradigm in machine\nlearning for modeling and exploiting the underlying graph structure that\ncaptures the relationship between labeled and unlabeled data. A large number of\nclassical as well as modern deep learning based algorithms have been proposed\nfor this problem, often having tunable hyperparameters. We initiate a formal\nstudy of tuning algorithm hyperparameters from parameterized algorithm families\nfor this problem. We obtain novel $O(\\log n)$ pseudo-dimension upper bounds for\nhyperparameter selection in three classical label propagation-based algorithm\nfamilies, where $n$ is the number of nodes, implying bounds on the amount of\ndata needed for learning provably good parameters. We further provide matching\n$\\Omega(\\log n)$ pseudo-dimension lower bounds, thus asymptotically\ncharacterizing the learning-theoretic complexity of the parameter tuning\nproblem. We extend our study to selecting architectural hyperparameters in\nmodern graph neural networks. We bound the Rademacher complexity for tuning the\nself-loop weighting in recently proposed Simplified Graph Convolution (SGC)\nnetworks. We further propose a tunable architecture that interpolates graph\nconvolutional neural networks (GCN) and graph attention networks (GAT) in every\nlayer, and provide Rademacher complexity bounds for tuning the interpolation\ncoefficient.",
    "published": "2025-02-18T15:16:23Z",
    "pdf_link": "http://arxiv.org/pdf/2502.12937v1"
  },
  {
    "title": "Graph Neural Networks for Databases: A Survey",
    "authors": "Ziming Li, Youhuan Li, Yuyu Luo, Guoliang Li, Chuxu Zhang",
    "summary": "Graph neural networks (GNNs) are powerful deep learning models for\ngraph-structured data, demonstrating remarkable success across diverse domains.\nRecently, the database (DB) community has increasingly recognized the\npotentiality of GNNs, prompting a surge of researches focusing on improving\ndatabase systems through GNN-based approaches. However, despite notable\nadvances, There is a lack of a comprehensive review and understanding of how\nGNNs could improve DB systems. Therefore, this survey aims to bridge this gap\nby providing a structured and in-depth overview of GNNs for DB systems.\nSpecifically, we propose a new taxonomy that classifies existing methods into\ntwo key categories: (1) Relational Databases, which includes tasks like\nperformance prediction, query optimization, and text-to-SQL, and (2) Graph\nDatabases, addressing challenges like efficient graph query processing and\ngraph similarity computation. We systematically review key methods in each\ncategory, highlighting their contributions and practical implications. Finally,\nwe suggest promising avenues for integrating GNNs into Database systems.",
    "published": "2025-02-18T14:51:50Z",
    "pdf_link": "http://arxiv.org/pdf/2502.12908v2"
  },
  {
    "title": "The Relationship Between Head Injury and Alzheimer's Disease: A Causal\n  Analysis with Bayesian Networks",
    "authors": "Andrei Lixandru",
    "summary": "This study examines the potential causal relationship between head injury and\nthe risk of developing Alzheimer's disease (AD) using Bayesian networks and\nregression models. Using a dataset of 2,149 patients, we analyze key medical\nhistory variables, including head injury history, memory complaints,\ncardiovascular disease, and diabetes. Logistic regression results suggest an\nodds ratio of 0.88 for head injury, indicating a potential but statistically\ninsignificant protective effect against AD. In contrast, memory complaints\nexhibit a strong association with AD, with an odds ratio of 4.59. Linear\nregression analysis further confirms the lack of statistical significance for\nhead injury (coefficient: -0.0245, p = 0.469) while reinforcing the predictive\nimportance of memory complaints. These findings highlight the complex interplay\nof medical history factors in AD risk assessment and underscore the need for\nfurther research utilizing larger datasets and advanced causal modeling\ntechniques.",
    "published": "2025-02-18T14:34:22Z",
    "pdf_link": "http://arxiv.org/pdf/2502.12898v1"
  },
  {
    "title": "Testing for Causal Fairness",
    "authors": "Jiarun Fu, LiZhong Ding, Pengqi Li, Qiuning Wei, Yurong Cheng, Xu Chen",
    "summary": "Causality is widely used in fairness analysis to prevent discrimination on\nsensitive attributes, such as genders in career recruitment and races in crime\nprediction. However, the current data-based Potential Outcomes Framework (POF)\noften leads to untrustworthy fairness analysis results when handling\nhigh-dimensional data. To address this, we introduce a distribution-based POF\nthat transform fairness analysis into Distributional Closeness Testing (DCT) by\nintervening on sensitive attributes. We define counterfactual closeness\nfairness as the null hypothesis of DCT, where a sensitive attribute is\nconsidered fair if its factual and counterfactual potential outcome\ndistributions are sufficiently close. We introduce the Norm-Adaptive Maximum\nMean Discrepancy Treatment Effect (N-TE) as a statistic for measuring\ndistributional closeness and apply DCT using the empirical estimator of NTE,\nreferred to Counterfactual Fairness-CLOseness Testing ($\\textrm{CF-CLOT}$). To\nensure the trustworthiness of testing results, we establish the testing\nconsistency of N-TE through rigorous theoretical analysis. $\\textrm{CF-CLOT}$\ndemonstrates sensitivity in fairness analysis through the flexibility of the\ncloseness parameter $\\epsilon$. Unfair sensitive attributes have been\nsuccessfully tested by $\\textrm{CF-CLOT}$ in extensive experiments across\nvarious real-world scenarios, which validate the consistency of the testing.",
    "published": "2025-02-18T14:05:04Z",
    "pdf_link": "http://arxiv.org/pdf/2502.12874v1"
  },
  {
    "title": "NTP-INT: Network Traffic Prediction-Driven In-band Network Telemetry for\n  High-load Switches",
    "authors": "Penghui Zhang, Hua Zhang, Yuqi Dai, Cheng Zeng, Jingyu Wang, Jianxin Liao",
    "summary": "In-band network telemetry (INT) is essential to network management due to its\nreal-time visibility. However, because of the rapid increase in network devices\nand services, it has become crucial to have targeted access to detailed network\ninformation in a dynamic network environment. This paper proposes an\nintelligent network telemetry system called NTP-INT to obtain more fine-grained\nnetwork information on high-load switches. Specifically, NTP-INT consists of\nthree modules: network traffic prediction module, network pruning module, and\nprobe path planning module. Firstly, the network traffic prediction module\nadopts a Multi-Temporal Graph Neural Network (MTGNN) to predict future network\ntraffic and identify high-load switches. Then, we design the network pruning\nalgorithm to generate a subnetwork covering all high-load switches to reduce\nthe complexity of probe path planning. Finally, the probe path planning module\nuses an attention-mechanism-based deep reinforcement learning (DEL) model to\nplan efficient probe paths in the network slice. The experimental results\ndemonstrate that NTP-INT can acquire more precise network information on\nhigh-load switches while decreasing the control overhead by 50\\%.",
    "published": "2025-02-18T13:00:52Z",
    "pdf_link": "http://arxiv.org/pdf/2502.12834v1"
  },
  {
    "title": "Learning Counterfactually Fair Models via Improved Generation with\n  Neural Causal Models",
    "authors": "Krishn Vishwas Kher, Aditya Varun V, Shantanu Das, SakethaNath Jagarlapudi",
    "summary": "One of the main concerns while deploying machine learning models in\nreal-world applications is fairness. Counterfactual fairness has emerged as an\nintuitive and natural definition of fairness. However, existing methodologies\nfor enforcing counterfactual fairness seem to have two limitations: (i)\ngenerating counterfactual samples faithful to the underlying causal graph, and\n(ii) as we argue in this paper, existing regularizers are mere proxies and do\nnot directly enforce the exact definition of counterfactual fairness. In this\nwork, our aim is to mitigate both issues. Firstly, we propose employing Neural\nCausal Models (NCMs) for generating the counterfactual samples. For\nimplementing the abduction step in NCMs, the posteriors of the exogenous\nvariables need to be estimated given a counterfactual query, as they are not\nreadily available. As a consequence, $\\mathcal{L}_3$ consistency with respect\nto the underlying causal graph cannot be guaranteed in practice due to the\nestimation errors involved. To mitigate this issue, we propose a novel kernel\nleast squares loss term that enforces the $\\mathcal{L}_3$ constraints\nexplicitly. Thus, we obtain an improved counterfactual generation suitable for\nthe counterfactual fairness task. Secondly, we propose a new MMD-based\nregularizer term that explicitly enforces the counterfactual fairness\nconditions into the base model while training. We show an improved trade-off\nbetween counterfactual fairness and generalization over existing baselines on\nsynthetic and benchmark datasets.",
    "published": "2025-02-18T11:59:03Z",
    "pdf_link": "http://arxiv.org/pdf/2502.12796v1"
  },
  {
    "title": "Circuit Representation Learning with Masked Gate Modeling and\n  Verilog-AIG Alignment",
    "authors": "Haoyuan Wu, Haisheng Zheng, Yuan Pu, Bei Yu",
    "summary": "Understanding the structure and function of circuits is crucial for\nelectronic design automation (EDA). Circuits can be formulated as And-Inverter\ngraphs (AIGs), enabling efficient implementation of representation learning\nthrough graph neural networks (GNNs). Masked modeling paradigms have been\nproven effective in graph representation learning. However, masking\naugmentation to original circuits will destroy their logical equivalence, which\nis unsuitable for circuit representation learning. Moreover, existing masked\nmodeling paradigms often prioritize structural information at the expense of\nabstract information such as circuit function. To address these limitations, we\nintroduce MGVGA, a novel constrained masked modeling paradigm incorporating\nmasked gate modeling (MGM) and Verilog-AIG alignment (VGA). Specifically, MGM\npreserves logical equivalence by masking gates in the latent space rather than\nin the original circuits, subsequently reconstructing the attributes of these\nmasked gates. Meanwhile, large language models (LLMs) have demonstrated an\nexcellent understanding of the Verilog code functionality. Building upon this\ncapability, VGA performs masking operations on original circuits and\nreconstructs masked gates under the constraints of equivalent Verilog codes,\nenabling GNNs to learn circuit functions from LLMs. We evaluate MGVGA on\nvarious logic synthesis tasks for EDA and show the superior performance of\nMGVGA compared to previous state-of-the-art methods. Our code is available at\nhttps://github.com/wuhy68/MGVGA.",
    "published": "2025-02-18T10:48:16Z",
    "pdf_link": "http://arxiv.org/pdf/2502.12732v1"
  }
]